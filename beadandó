import pandas as pd
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt

spy = pd.read_csv('SPY.csv', parse_dates=['Date'])
sbux = pd.read_csv('SBUX.csv', parse_dates=['Date'])
sbux.head()
spy.head()

#1. feladat
#Napi hozamok kiszámítása
spy_ret = spy['Close'].pct_change().dropna()
sbux_ret = sbux['Close'].pct_change().dropna()
spy_ret.head()

# Portfólió hozamának és varianciájának kiszámítása különböző súlyok mellett (0-1)
weights = np.arange(0, 1.1, 0.1)

portfolio_variances = []
portfolio_returns = []
portfolio_avg_ret = []

for w in weights:
    portfolio_returns.append(w * spy_ret + (1 - w) * sbux_ret)
    portfolio_variances.append(portfolio_returns[-1].var())
    portfolio_avg_ret.append(w * np.mean(spy_ret) + (1 - w) * np.mean(sbux_ret))

portfolio_avg_ret = pd.DataFrame(portfolio_avg_ret, columns = ['Returns'])
portfolio_avg_ret.head()

# A hozamok ábrája
plt.subplot(1, 2, 1) 
plt.plot(weights, portfolio_avg_ret, marker='o')
plt.xlabel('Portfolio Weight')
plt.ylabel('Returns')
plt.title('Portfolio Returns')

# A varianciák ábrája
plt.subplot(1, 2, 2) 
plt.plot(weights, portfolio_variances, marker='o')
plt.xlabel('Portfolio Weight')
plt.ylabel('Variances')
plt.title('Portfolio Variances')

plt.tight_layout()

plt.show()

# Az ábrákon az látszik, hogy ahogyan csökkentjük a Starbucks részvény súlyát a portfóliónkban úgy csökken a varianca,
# azonban a hozamok is úgy csökkennek.

# Autograde function
def calculate_historical_var(df_portfolio_returns, alpha):
    sorted_returns = np.sort(df_portfolio_returns)
    var_idx = int(np.floor(alpha * len(sorted_returns)))
    return sorted_returns[var_idx]

# Példa a függvény használatára
alpha = 0.05  # Confidence level for VaR

for i in range(len(weights)):
    var = calculate_historical_var(portfolio_returns[i], alpha)
    print(f"For weight {weights[i]:.1f}, VaR at {alpha*100}% confidence level: {var:.4f}")
