# A kód a Starbucks (sbux) és SPDR S&P 500 ETF (spy) historikus adataival dolgozik.
# Az adatok az elmúlt 5 évből vannak a 2018.06.18.-2023.06.17.-ig terjedő időszakra.

# Packagek importálása
import random
import pandas as pd
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt

# seed beállítása és adatok beolvasása
random.seed(31415)
spy = pd.read_csv('SPY.csv', parse_dates=['Date'])
sbux = pd.read_csv('SBUX.csv', parse_dates=['Date'])
sbux.head()
spy.head()

#Starbucks ábra
plt.plot(sbux.Date, sbux.Close)
plt.xlabel('Date')
plt.ylabel('SBUX')
plt.title('Starbucks stock value')

plt.tight_layout()

plt.show()

# SPY ábra

plt.plot(spy.Date, spy.Close)
plt.xlabel('Date')
plt.ylabel('SBUX')
plt.title('S&P 500 ETF value')

plt.tight_layout()

plt.show()

#1. feladat
#Napi hozamok kiszámítása
spy_ret = spy['Adj Close'].pct_change().dropna()
sbux_ret = sbux['Adj Close'].pct_change().dropna()
spy_ret.head()

# Portfólió hozamának és varianciájának kiszámítása különböző súlyok mellett (0-1)
weights = np.arange(0, 1.1, 0.1)

portfolio_variances = []
portfolio_returns = []
portfolio_avg_ret = []

for w in weights:
    portfolio_returns.append(w * spy_ret + (1 - w) * sbux_ret)
    portfolio_variances.append(portfolio_returns[-1].var())
    portfolio_avg_ret.append(w * np.mean(spy_ret) + (1 - w) * np.mean(sbux_ret))

portfolio_avg_ret = pd.DataFrame(portfolio_avg_ret, columns = ['Returns'])
portfolio_avg_ret.head()

# A hozamok ábrája
plt.subplot(1, 2, 1) 
plt.plot(weights, portfolio_avg_ret, marker='o')
plt.xlabel('Portfolio Weight')
plt.ylabel('Returns')
plt.title('Portfolio Returns')

# A varianciák ábrája
plt.subplot(1, 2, 2) 
plt.plot(weights, portfolio_variances, marker='o')
plt.xlabel('Portfolio Weight')
plt.ylabel('Variances')
plt.title('Portfolio Variances')

plt.tight_layout()

plt.show()

# Az ábrákon az látszik, hogy ahogyan csökkentjük a Starbucks részvény súlyát a portfóliónkban úgy csökken a varianca,
# azonban a hozamok is úgy csökkennek.

# Autograde function
def calculate_historical_var(df_portfolio_returns, alpha):
    sorted_returns = np.sort(df_portfolio_returns)
    var_idx = int(np.floor(alpha * len(sorted_returns)))
    return sorted_returns[var_idx]

# Példa a függvény használatára
alpha = 0.95  # Confidence level for VaR

for i in range(len(weights)):
    var = calculate_historical_var(portfolio_returns[i], alpha)
    print(f"For weight {weights[i]:.1f}, VaR at {alpha*100}% confidence level: {var:.4f}")

# 2.feladat

expected_return_spy = np.mean(spy_ret)
expected_return_sbux = np.mean(sbux_ret)

volatility_spy = spy_ret.var()
volatility_sbux = sbux_ret.var()

correlation = 0.5

weight_spy = 1 / volatility_spy
weight_sbux = 1 / volatility_sbux
total_weight = weight_spy + weight_sbux
weight_spy /= total_weight
weight_sbux /= total_weight

print(weight_spy, weight_sbux)

# Autograde Function: simulated_returns
def simulated_returns(expected_return, volatility, correlation, num_of_sim):
    cov_matrix = np.array([[volatility**2, correlation * volatility * volatility],
                          [correlation * volatility * volatility, volatility**2]])
    simulated_returns = np.random.multivariate_normal([expected_return, expected_return], cov_matrix, num_of_sim)
    return simulated_returns

# Hozam szimuláció a két eszközre
num_of_simulations = 10000
simulated_returns_spy = simulated_returns(expected_return_spy, volatility_spy, 1.0, num_of_simulations)
simulated_returns_sbux = simulated_returns(expected_return_sbux, volatility_sbux, 1.0, num_of_simulations)

# Portfólió létrehozása
portfolio_returns = weight_spy * simulated_returns_spy + weight_sbux * simulated_returns_sbux

print(portfolio_returns[1])

portfolio_returns_1 = []

for i in range(len(portfolio_returns)):
  portfolio_returns_1.append(portfolio_returns[i][1])

# VaR
alpha = 0.05  # Confidence level for VaR
sorted_returns = np.sort(portfolio_returns_1)
var_idx = int(np.floor(alpha * num_of_simulations))
var = sorted_returns[var_idx]

# Különböző korrelációk melletti VaR
VaRs = []

correlations = np.arange(0, 1.1, 0.05)
for corr in correlations:
    # Hozam szimuláció a két eszközre
    num_of_simulations = 10000
    simulated_returns_spy = simulated_returns(expected_return_spy, volatility_spy, corr, num_of_simulations)
    simulated_returns_sbux = simulated_returns(expected_return_sbux, volatility_sbux, corr, num_of_simulations)

    # Portfólió létrehozása
    portfolio_returns = weight_spy * simulated_returns_spy + weight_sbux * simulated_returns_sbux
    portfolio_returns_1 = []

    for i in range(len(portfolio_returns)):
      portfolio_returns_1.append(portfolio_returns[i][1])

    # VaR
    alpha = 0.05  # Confidence level for VaR
    sorted_returns = np.sort(portfolio_returns_1)
    var_idx = int(np.floor(alpha * num_of_simulations))
    var = sorted_returns[var_idx]
    VaRs.append(var)

print(VaRs)

plt.plot(correlations, VaRs, marker='o')
plt.title('VaR vs. Correlation')
plt.xlabel('Correlation')
plt.ylabel('VaR')
plt.grid(True)
plt.show()
